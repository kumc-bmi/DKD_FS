##################################################################
# Step 2 -- estimate percentage of featrue selected              #
#        -- retrain with different subset of features            # 
#        -- test on both hold-in and hold-out set                #
#        -- record out-of-sample AUC and Kuncheva index          #
##################################################################

##set up
rm(list=ls()); gc()
source("./helper_functions.R")
require_libraries("devtools")
slam_url<-"https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
require_libraries(c( "Matrix"
                    ,"pROC"
                    ,"h2o"
                    ,"dplyr"
                    ,"tidyr"
                    ,"magrittr"
                    ,"data.table"
                    ,"slam"
))

##load data
resamples<-10 #random sampling param
boots<-20 #boostrapping
load("DKD_heron_pats_prep.Rdata")
load("DKD_heron_facts_prep.Rdata")

load(paste0("random_sample",resamples,".Rdata"))
load("dl_feature_boot.Rdata")
load("dl_prediction_boot.Rdata")
load("feature_dict.Rdata")

##global values
#can be set to range of values
hyper_params<-list(
  activation=c("Rectifier"), #default
  hidden=list(c(64,64),c(128,128),c(64,64,64),c(128,128,128)),
  input_dropout_ratio=0.1,   #common choice: 0.1,0.2
  l1=1e-5,  #default
  l2=1e-5   #default
)

search_criteria<-list(
  strategy = "RandomDiscrete",
  max_runtime_secs = 360,
  max_models = 100,
  stopping_rounds=5,
  stopping_tolerance=1e-2
)

# feat_sel_rt<-c(0.25,0.1,0.05,0.02,0.01,0.005) #feature selection ratio
# feat_sel_k<-length(unique(fact_stack$CONCEPT_CD))*feat_sel_rt
feat_sel_k_low<-13
feat_sel_k_up<-200
feat_sel_k_inc<-1.5
auc_inc_tol<-0.01
inc_tol_p<-0.005
s<-c(50,100) # number of top rank of interests
overall_y_sort<-pat_tbl %>% semi_join(fact_stack,by="PATIENT_NUM") %>% 
  arrange(PATIENT_NUM) %>% dplyr::select(DKD_IND) %>% unlist

# ensemble feature, tune, train, predict and evaluate stability
#initialization
feature_rk<-list()
feature_eff<-list()
time_perf<-list()

#initialize h2o
h2o.init(nthreads=-1)

#start experiment
for(i in 1:10){
  start_i<-Sys.time()
  cat("start resample:",i,"\n")
  time_perf_i_nm<-c() #track task
  time_perf_i<-c()    #track time
  
  #########################################################
  #####ensemble and select features
  start_k<-Sys.time()
  cat("...ensemble features \n")
  
  feature_i<-c()
  pred_real_i<-pred_real[[paste0("resample",i)]]
  oob_auc<-pred_real_i %>% ungroup %>%
    dplyr::filter(part73 == "OOB") %>%
    dplyr::select(boot,pred,real) %>%
    group_by(boot) %>%
    dplyr::summarize(oob_weight=pROC::auc(real,pred))
  
  for(b in 1:boots){
    feature_i %<>% 
      bind_rows(feature_lst[[paste0("resample",i,"boot",b)]] %>%
                  dplyr::select(Feature,scaled_importance)%>%
                  mutate(rank=rank(-scaled_importance),boot=b))
  }
  
  feature_i  %<>%
    left_join(oob_auc,by="boot") %>%
    mutate(wt_rank=rank*oob_weight,
           top_50_f=(rank<=s[1])*1,
           top_100_f=(rank<=s[2])*1,
           wt_top_50_f=(rank<=s[1])*oob_weight,
           wt_top_100_f=(rank<=s[2])*oob_weight,
           top_50_exp_f=exp(-rank/s[1]),
           top_100_exp_f=exp(-rank/s[2]),
           wt_top_50_exp_f=(exp(-rank/s[1]))*oob_weight,
           wt_top_100_exp_f=(exp(-rank/s[2]))*oob_weight) %>%
    group_by(Feature) %>%
    dplyr::summarize(sel_cnt=length(unique(boot)),
                     best_rank=min(rank,na.rm=T),
                     worst_rank=max(rank,na.rm=T),
                     mean_rank=mean(rank,na.rm=T),   
                     wt_mean_rank=sum(wt_rank)/sum(oob_weight),   
                     top_50=-mean(top_50_f),
                     wt_top_50=-sum(wt_top_50_f)/sum(oob_weight),
                     top_100=-mean(top_100_f),
                     wt_top_100=-sum(wt_top_100_f)/sum(oob_weight),
                     top_50_exp=-mean(top_50_exp_f),
                     wt_top_50_exp=-sum(wt_top_50_exp_f)/sum(oob_weight),
                     top_100_exp=-mean(top_100_exp_f),
                     wt_top_100_exp=-sum(wt_top_100_exp_f)/sum(oob_weight)) %>%
    full_join(feature_lst[[paste0("resample",i,"single")]] %>%
                dplyr::select(Feature,scaled_importance) %>%
                mutate(single_rank=rank(-scaled_importance)) %>%
                dplyr::select(Feature,single_rank), by="Feature")
  
  time_perf_i_nm<-c(time_perf_i_nm,"ensemble_feature")
  time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_k,units(Sys.time()-start_k)))
  cat("...finish ensembling features in",time_perf_i[length(time_perf_i)],"\n")
  
  pred_mt_fs_i<-c()
  feat_topk_eff_i<-c()
  ################################################################
  ####experiment on different selection ratio
  fs_mth<-colnames(feature_i)[-c(1:4,7:8,11:12)]
  for(fs in seq_along(fs_mth)){
    start_fs<-Sys.time()
    cat("...rank feature importance based on",fs_mth[fs],"\n")
    
    #####train a classifier with selected features
    dat_sample_i<-dat_resample_rand[[paste0("resample",i)]] %>%
      arrange(PATIENT_NUM) #sort by patient_num
    
    #####adaptive feature inclusion
    #initialization
    feat_sel_k<-feat_sel_k_low
    auc_inc<--Inf
    inc_p<-1
    ROC_obj_new<-pROC::roc(overall_y_sort[(dat_sample_i$part73!="T")],
                           sample(c(0,1),nrow(dat_sample_i[(dat_sample_i$part73!="T"),]),replace=T),
                           direction="<") ## random chance
    
    #exit condition
    stop_cond<-paste0("(feat_sel_k > feat_sel_k_up)","&&",                                       ## reach upper bound  OR
                      "(",
                         "(auc_inc >= 0 && (inc_p >= inc_tol_p || auc_inc <= auc_inc_tol))","||",## insignificant improvement  OR
                         "(auc_inc < 0 && inc_p <= inc_tol_p)",                                  ## significant drop
                       ")")                                  
    
    while(!eval(parse(text=stop_cond))){
      #update current best ROC curve and increase feat_sel_k
      ROC_obj_opt<-ROC_obj_new
      feat_sel_k<-round(feat_sel_k_inc*feat_sel_k)
      
      start_j<-Sys.time()
      cat("...keep",feat_sel_k,"features \n")

      #####################################################################################
      start_k<-Sys.time()
      cat("......subset features and transform to wide sparse matrix \n")
      
      fs_sel<-feature_i %>%
        mutate(rk=get(fs_mth[fs])) %>% 
        arrange(rk) %>% dplyr::select(Feature,rk) %>% 
        dplyr::slice(1:feat_sel_k)
        
      x_sparse_val<-fact_stack %>% 
        semi_join(fs_sel, by=c("CONCEPT_CD"="Feature")) %>%    #subset features
        inner_join(dat_sample_i,by=c("PATIENT_NUM")) %>% 
        dplyr::select(-part73) %>%
        group_by(PATIENT_NUM) %>%
        long_to_sparse_matrix(.,id="PATIENT_NUM",
                              variable="CONCEPT_CD",
                              val="NVAL_NUM") #sort by patient_num
      
      if(dim(x_sparse_val)[1]<dim(dat_sample_i)[1]){
        dat_sample_i %<>%
          semi_join(data.frame(PATIENT_NUM=as.numeric(rownames(x_sparse_val))),
                    by="PATIENT_NUM") #shrink feature space will reduce training data size as well
      }
    
      x_sparse_pat<-pat_tbl %>%
        semi_join(dat_sample_i,by="PATIENT_NUM") %>%
        arrange(PATIENT_NUM) %>%
        gather(key,value,-PATIENT_NUM) %>%
        semi_join(bind_rows(fs_sel,
                            data.frame(Feature="DKD_IND",rk=0,stringsAsFactors=F)),
                  by=c("key"="Feature")) %>%    #subset features
        long_to_sparse_matrix(.,id="PATIENT_NUM",
                              variable="key",
                              val="value") #sort by patient_num
    
      #record real y values
      dat_sample_i[,"real"]<-x_sparse_pat[,which(colnames(x_sparse_pat)=="DKD_IND")]
      
      time_perf_i_nm<-c(time_perf_i_nm,paste0("subset_feature_transform@",fs,"@",feat_sel_k))
      time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_k,units(Sys.time()-start_k)))
      cat("......finish subsetting and transforming in",time_perf_i[length(time_perf_i)],"\n")
    
      #######################################################################################
      start_k<-Sys.time()
      cat("......separate training and testing sets \n")
    
      train_mt<-cbind(x_sparse_pat[(dat_sample_i$part73=="T"),],
                      x_sparse_val[(dat_sample_i$part73=="T"),])
      colnames(train_mt)<-c(colnames(x_sparse_pat),colnames(x_sparse_val)) #colname may be dropped when only one column is selected
      
      test_mt<-cbind(x_sparse_pat[(dat_sample_i$part73!="T"),],
                     x_sparse_val[(dat_sample_i$part73!="T"),])
      colnames(test_mt)<-c(colnames(x_sparse_pat),colnames(x_sparse_val)) #colname may be dropped when only one column is selected
      
      time_perf_i_nm<-c(time_perf_i_nm,paste0("partition@",fs,"@",feat_sel_k))
      time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_k,units(Sys.time()-start_k)))
      cat("......finish partitioning in",time_perf_i[length(time_perf_i)],"\n") 
      
      ######################################################################################
      start_k<-Sys.time()
      cat("......tune, train and predict \n")
      
      train_h2o<-as.h2o(train_mt) # column order doesn't change
      test_h2o<-as.h2o(test_mt) # column order doesn't change
      pred_idx<-which(colnames(train_mt)!="DKD_IND")
      target_idx<-which(colnames(train_mt)=="DKD_IND")
      
      train_h2o[,target_idx]<-as.factor(train_h2o[,target_idx]) 
      dl_random_grid <- h2o.grid(
        algorithm="deeplearning",
        grid_id = "dl_grid_random",
        training_frame=train_h2o,
        nfolds=5,
        keep_cross_validation_predictions =T,
        x=pred_idx,
        y=target_idx,
        distribution="bernoulli",
        standardize=T,
        epochs=50,                     ## make it fast
        stopping_metric="logloss",
        stopping_tolerance=1e-2,        ## stop when logloss does not improve by >=1% for 2 scoring events
        stopping_rounds=2,
        score_duty_cycle=0.025,         ## don't score more than 2.5% of the wall time
        max_w2=10,                      ## can help improve stability for Rectifier
        sparse=T,
        hyper_params = hyper_params,
        search_criteria = search_criteria,
        variable_importances=T          ## track variable importance
      )
      
      ## pick out the optimal model
      dlr_grid<-h2o.getGrid("dl_grid_random",sort_by="auc",decreasing=T)
      flr_opt_model<-h2o.getModel(dlr_grid@model_ids[[1]])
      flr_hyper_params<-flr_opt_model@parameters
      
      dat_sample_i[,"hidden"]<-paste(flr_opt_model@parameters$hidden,collapse = "_")
      dat_sample_i[,"input_dropout_ratio"]<-flr_opt_model@parameters$input_dropout_ratio
      dat_sample_i[(dat_sample_i$part73=="T"),"pred"]<-as.data.frame(predict(flr_opt_model,train_h2o))$p1
      dat_sample_i[(dat_sample_i$part73!="T"),"pred"]<-as.data.frame(predict(flr_opt_model,test_h2o))$p1
      
      # evaluate auc improvement
      cvpreds<-h2o.getFrame(flr_opt_model@model[["cross_validation_holdout_predictions_frame_id"]][["name"]]) # row sorted, matched with h2o.auc(flr_opt_model,xval=T)
      ROC_obj_new<-pROC::roc(dat_sample_i[(dat_sample_i$part73=="T"),]$real,
                             as.data.frame(cvpreds)$p1)
      auc_inc<-ROC_obj_new$auc-ROC_obj_opt$auc
      inc_p<-roc.test(ROC_obj_new,ROC_obj_opt,method="delong")$p.value
      
      pred_mt_fs_i %<>%
        bind_rows(dat_sample_i %>% mutate(fs_num=feat_sel_k,
                                          fs=fs_mth[fs],
                                          auc_at=ROC_obj_new$auc,
                                          auc_inc=auc_inc,
                                          auc_inc_pval=inc_p))
    
      time_perf_i_nm<-c(time_perf_i_nm,paste0("tune_train_predict@",fs,"@",feat_sel_k))
      time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_k,units(Sys.time()-start_k)))
      cat("......finish tuning, training and predicting in",time_perf_i[length(time_perf_i)],"\n")
      
      ######################################################################################
      #####3-points feature effect (for top k)
      k<-20
      start_k<-Sys.time()
      cat("......evaluate paritial effect of top",k,"features \n")

      feat_ij<-h2o.varimp(flr_opt_model) %>%
        left_join(data.frame(Feature=colnames(train_mt),
                             col_code=paste0("C",seq_len(ncol(train_mt))),
                             stringsAsFactors = FALSE),
                  by=c("variable"="col_code")) %>%
        dplyr::slice(1:k) %>%
        dplyr::select(Feature,variable,scaled_importance,percentage) %>%
        left_join(feat_dict,by=c("Feature"="CONCEPT_CD")) %>% unique #decode

      k<-min(k,nrow(feat_ij))
      train_h2o_part<-h2o.splitFrame(train_h2o,0.99)[[1]]
      feat_eff_kij<-c()
      for(kij in 1:k){
        #variable of interest
        pred_var<-feat_ij$Feature[kij]
        pred_code<-feat_ij$variable[kij]

        #3-points effect
        pred_grid<-feat_ij %>% dplyr::slice(kij) %>%
          dplyr::select(distinct_val,low,mid,high)
        
        yhat<-c()
        if(pred_grid$distinct_val==1){
          bins<-c(pred_grid$low,pred_grid$high)
        }else{
          bins<-c(pred_grid$low,pred_grid$mid,pred_grid$high)
        }

        for(val in bins){
          train_h2o_part[,pred_code]<-val
          response<-h2o.predict(flr_opt_model,train_h2o_part)
          mean_response<-mean(response[,ncol(response)])
          yhat<-c(yhat,mean_response)
        }
       
        feat_eff_kij<-rbind(feat_eff_kij,
                            cbind(Feature=pred_var,
                                  Low=yhat[1],
                                  Mid=ifelse(pred_grid$distinct_val==1,NA,yhat[2]),
                                  High=ifelse(pred_grid$distinct_val==1,yhat[2],yhat[3])))
      }

      feat_topk_eff_i %<>%
        bind_rows(feat_ij %>%
                    inner_join(data.frame(feat_eff_kij,stringsAsFactors=FALSE),by="Feature") %>%
                    mutate(fs_mth=fs_mth[fs],fs_num=feat_sel_k))

      time_perf_i_nm<-c(time_perf_i_nm,paste0("partial_effect@",fs,"@",feat_sel_k))
      time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_k,units(Sys.time()-start_k)))
      cat("......finish evaluating paritial effect in",time_perf_i[length(time_perf_i)],"\n")
      
      #####################################################################################
      time_perf_i_nm<-c(time_perf_i_nm,paste0("finish_eval_feature_num@",fs,"@",feat_sel_k))
      time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_j,units(Sys.time()-start_j)))
      cat("......finish modeling on",feat_sel_k,"features in",time_perf_i[length(time_perf_i)],"\n")
      
      h2o.removeAll()
      }
    
    #end inner loop
    time_perf_i_nm<-c(time_perf_i_nm,paste0("fs_method_eval_end@",fs,"@",feat_sel_k))
    time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_fs,units(Sys.time()-start_fs)))
    cat("...finish evaluating feature ensemble method:",fs_mth[fs],"in",time_perf_i[length(time_perf_i)],"\n")
  }
  
  pred_real[[paste0("resample",i)]]<-pred_mt_fs_i
  feature_rk[[paste0("resample",i)]]<-feature_i
  # feature_eff[[paste0("resample",i)]]<-feat_topk_eff_i
  
  #end outer loop
  time_perf_i_nm<-c(time_perf_i_nm,paste0("completion_at_resample@",fs,"@",feat_sel_k))
  time_perf_i<-c(time_perf_i,paste0(Sys.time()-start_i,units(Sys.time()-start_i)))
  cat("finish evaluating resample",i,"in",time_perf_i[length(time_perf_i)],"\n")
  
  time_perf[[i]]<-data.frame(task=time_perf_i_nm,
                             time=time_perf_i)
}

# save results
save(pred_real,file="dl_prediction_fs.Rdata")
save(feature_rk,file="dl_feature_rank_boot.Rdata")
save(feature_eff,file="dl_feature_topk_eff.Rdata")
save(time_perf,file="dlerformance2_boot.Rdata")

h2o.shutdown(prompt = FALSE)
